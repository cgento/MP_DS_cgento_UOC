\chapter{Estado del Arte}
\label{chapter:attrition}
\section{Causas del Panel Attrition}
\label{section:causes_attrition}

Tal y como hemos mencionado en la introducción, los métodos adaptativos y reactivos buscan implementar intervenciones en los procesos de creación de datos de encuestas. Para poder implementarlas para reducir el abandono de panelistas, es importante conocer qué provoca el abandono de los hogares panelistas. Conceptualmente, las causas del Panel Attrition pueden clasificarse en tres categorías secuenciales (\cite{lepkowski2002nonresponse}): no-localización, no-contacto y no-cooperación.

La no-localización se refiere a no localizar exitosamente a un encuestado durante una ola posterior. Generalmente, esto se debe a cambios en la información de contacto (dirección de residencia, número teléfono, correo electrónico...) obtenida del participante durante la ola anterior (\cite{couper2009keeping}). Algunos factores que pueden contribuir al éxito o fracaso en la localización son el método de recolección de datos, la propensión a los cambios de localización de los encuestados entre diferentes olas, el tiempo transcurrido entre olas e incluso el presupuesto (\cite{lynn2009methods}). Por ejemplo, las encuestas con entrevistas cara a cara utilizan métodos de rastreo y búsqueda que suelen ofrecer altos índices de localización y cooperación (\cite{de2005mix}, \cite{couper2009keeping}), pero también requieren esfuerzos adicionales para localizar a los participantes panel que se hayan mudado, como por ejemplo reembolsar a los entrevistadores los gastos derivados del proceso de búsqueda.

La segunda causa es el no-contacto. Tras localizar exitosamente al encuestado, es necesario establecer un contacto. Para que sea exitoso, es necesario que el intento de contacto por parte de los encuestadores coincida temporalmente con la disponibilidad del panelista. Esto depende completamente del método de recolección de los datos. Por ejemplo, en una entrevista personal, el panelista debe estar en su residencia justo en el mismo momento en el que la persona que quiere entrevistarle hace la visita al hogar. Algo parecido sucede con las entrevistas telefónicas, ya que el panelista debe tener su teléfono accesible cuando se realiza la llamada para intentar el contacto. Tradicionalmente, dos estrategias de contacto que han presentado buenos resultados han sido utilizar un número de intentos de contacto alto y diversificado en horarios (mañana, tarde, fines de semana...), y establecer períodos para realizar entrevistas lo suficientemente largos (\cite{nicoletti2005survey}, \cite{watson2009identifying}).

Finalmente, tras establecer el contacto, es necesario convencer al panelista para que vuelva a participar otra vez en la encuesta. La falta de cooperación es una preocupación común en todo tipo de encuestas, y suelen destacar factores como las características socio-demográficas de los encuestados o la temática de la encuesta (\cite{groves1992understanding}). En el caso particular de las encuestas longitudinales, los encuestados además poseen una experiencia previa por haber participado en ediciones pasadas. Esto hace que sea relativamente probable que vuelvan a hacerlo, en parte por ser consistentes con su comportamiento de conformidad mostrado anteriormente (\cite{groves1992understanding}), pero también puede potenciar el efecto negativo de factores como la duración de la entrevista, la carga cognitiva que supone pensar algunas respuestas o la fatiga por haber participado en varias ediciones anteriores (\cite{laurie1999strategies}, \cite{watson2009identifying}, \cite{lynn2018tackling}).

En el siguiente apartado se comenta cómo la disponibilidad de información sobre todas estas causas puede ser aprovechada por los algoritmos de machine learning para crear modelos que ayuden a predecir Panel Attrition, y posibilitar la implementación de diseños adaptativos y reactivos con el objetivo de reducir el abandono de hogares panelistas en encuestas longitudinales.

Dentro de este contexto de diseños adaptativos y reactivos, en las últimas décadas destaca el desarrollo del uso de algoritmos de machine learning en la metodología de encuestas, y en particular para predecir no-respuesta y Panel Attrition (\cite{buskirk2018introduction}, \cite{kern2019tree}). Se comenta con más detalle en el siguiente apartado.

\section{Predicción de Panel Attrition con machine learning}

Los modelos utilizados en metodología de encuestas pueden clasificarse en dos categorías según sus objetivos: modelos para explicar, y modelos para predecir. Los modelos explicativos utilizan toda la información disponible para explorar las relaciones entre diferentes variables observadas, identificar causalidad entre ellas y realizar ejercicios de inferencia y contrastes de hipótesis. Los modelos predictivos, en cambio, buscan predecir o clasificar con precisión el valor de ciertas variables para escenarios que todavía no han ocurrido. Por construcción, sólo utilizan la información disponible antes de que ocurra el suceso a predecir. Aunque los modelos basados en métodos de machine learning pueden ser utilizados para ambas tareas, son particularmente interesantes para realizar tareas de predicción. En \cite{buskirk2018introduction} destacan particularmente la flexibilidad de los modelos de machine learning con respecto a otros modelos tradicionales utilizados en la metodología de encuestas, como la regresión logística o los mínimos cuadrados ordinarios (OLS). Para muchos algoritmos de machine learning no es necesario hacer supuestos sobre las distribuciones de las variables, hacer una especificación explícita de las relaciones entre variables antes de estimar los modelos, y además soportan el uso de un gran número de variables. Esto les permite detectar patrones y relaciones complejas entre variables y los convierte en una herramienta muy útil para realizar tareas de predicción.

En el contexto de la predicción del Panel Attrition, muchos estudios comparan el rendimiento de modelos de machine learning con el de modelos que se han utilizado tradicionalmente para analizar Panel Attrition, generalmente una regresión logística o Logit de efectos principales, es decir, sin considerar interacciones entre variables ni relaciones no linales. En \cite{kern2019tree} y \cite{kern2021predicting} utilizan datos de dos paneles de hogares en alemania para comparar el rendimiento de un Logit con varios modelos basados en árboles de decisión. Los resultados son prometedores ya que todos los modelos basados en árboles mostraron mejores rendimientos que el Logit, y además destacan por su facilidad para ser interpretados.

Otro ejemplo prometedor, y que además sirve para implementar un diseño adaptativo, puede verse en \cite{beste2023case}. Este estudio se divide en dos partes. En primer lugar, se utiliza información de ediciones pasadas de una encuesta a hogares en alemania para comparar, de nuevo, el rendimiento de un Logit con un algoritmo k-nearest neighbours (kNN), un árbol de clasificación (CART), un Random Forest (RF) y un Gradient Boosting Machine (GBM). El modelo que ofreció mejores resultados fue el Random Forest. Y en la segunda parte, utilizaron ese modelo de Random Forest para identificar hogares panelistas con una baja propensión a participar en la edición siguiente de la encuesta. Esa información les sirvió para crear un diseño experimental en el cual se asignaba un incentivo monetario adicional a la mitad de ésos hogares. Los resultados del experimento mostraron incrementos en las tasas de respuesta de los hogares tratados, y animaron a sus responsables a seguir utilizando este diseño adaptativo en futuras ediciones.

Aunque sin duda estos resultados son prometedores, es importante recalcar que deben ser contextualizados y valorados para cada caso particular de análisis. Por ejemplo, en \cite{liu2020using} se utiliza un panel de individuos en Estados Unidos para predecir la participación de panelistas en la segunda edición de dicha encuesta, y se compara de nuevo el rendimiento de un Logit con los de un Random Forest (RF), un modelo de Máquinas de Soporte Vectorial (SVM) y un LASSO. Sólo el LASSO mostró una mejora con respecto al modelo de regresión logística. Otro ejemplo puede verse en \cite{jankowsky2022validation}. En este estudio se compara el rendimiento de un modelo Logit con el de un modelo GBM (Gradient Boosting Machine) en dos encuestas con diseños bastante diferentes (una encuesta es en EEUU y la otra en alemania, una se ha realizado cada nueve años y la otra anualmente, una es telefónica y la otra es una entrevista presencial...). Para ambas encuestas apenas se observa que el GBM mejore los resultados de la regresión logística.

Como resumen, podemos decir que los algoritmos de machine learning poseen características que los hacen atractivos como herramientas de apoyo para el desarrollo de diseños adaptativos y reactivos en el área de la metodología de encuestas, y en particular para predecir Panel Attrition. De manera particular, algunos modelos, especialmente los basados en árboles de decisión, han mostrado buenos resultados a la hora de predecir la participación de panelistas en futuras ediciones de encuestas longitudinales. Sin embargo, es importante recalcar que estos resultados no son necesariamente generalizables a cualquier tipo de encuestas, y su uso debe ser valorado para cada caso en particular.
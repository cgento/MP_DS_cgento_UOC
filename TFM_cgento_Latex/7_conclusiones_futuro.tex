\chapter{Conclusiones y líneas de trabajo futuras}
\label{chapter:conclusiones}

El objetivo principal de este Trabajo de Fin de Máster es desarrollar un modelo basado en algoritmos de machine learning que ayude a predecir si un hogar panel de la Encuesta Financiera de las Familias (EFF) dejará de participar en la siguiente edición. Para ello, se ha seguido la implementación de entrenamiento y evaluación realizada en \cite{beste2023case}, pero adaptada al caso de estudio de la EFF.

Este trabajo se ha divido en dos piezas de análisis. La primera es un análisis exploratorio de las variables de la EFF y ver su posible relación con la participación de los hogares en la siguiente edición. En la segunda se entrenan cuatro modelos basados en algoritmos de machine learning (CART, Random Forest, XGBooster y Naïve-Bayes) para predecir el Panel Attrition en la EFF2020 con datos de la EFF2017, y a continuación se compara y evalúa su rendimiento comparado con el ofrecido por un modelo de Regresión Logística de efectos principales, que es un modelo que se ha utilizado tradicionalmente para analizar el Panel Attrition.

El trabajo de análisis exploratorio ha sido muy extenso y complejo porque ha requerido manejar y combinar un total de doce ficheros de datos repartidos entre tres ediciones de la EFF. Siete de ellos contenían registros de hogares, otros dos registros de incidencias, otros dos registros de pantallas de interacción con un software y el último era un censo de entrevistadores. Además, dos de los ficheros contenían más de 6,000 variables, y otros dos más de 600. En una misma edición de la encuesta había algunas variables duplicadas en diferentes ficheros, y también algunas variables comunes entre olas tenían diferentes codificaciones dependiendo de la ola. Tras eliminar duplicados, redundancias y homogeneizar variables, se consiguió un conjunto de datos manejable.

El análisis exploratorio ha mostrado varios resultados interesantes que pueden ser útiles para hacer implementaciones de diseños adaptativos. La proporción de hogares panel que no participaron en la EFF2020 era mayor para hogares que en 2017 participaron por primera vez, se mostraron más recelosos, no consintieron grabar la entrevista, la realizaron con un proxy. También lo era en aquellos hogares cuya PR en 2017 tenía un menor nivel de estudios, tenía menos de 35 años o más de 74, mostraron un menor nivel de satisfacción con su vida y un menor interés durante la entrevista. Finalmente, la proporción de abandonos en 2020 también fue mayor para los hogares cuya renta de 2017 se situaba en las tres quintilas inferiores de la distribución de renta de los hogares españoles en 2017, su riqueza bruta en 2017 se encontrada en dos las quintilas inferiores de la distribución de riqueza bruta de todos los hogares españoles en 2017, y si no poseían deudas. Toda esta información puede ser útil para un entrevistador que va a visitar a un hogar panel porque puede adaptar los argumentos que utilice para convencerles. Por ejemplo, si el hogar se mostró receloso en la edición anterior, puede ser más útil enfocarse en hablar sobre la confidencialidad de la encuesta que la presencia del estudio en los medios de comunicación.

En la parte del entrenamiento y evaluación de los modelos de machine learning, ninguno de los modelos de mahcine learning entrenados llega a superar el rendimiento del modelo de Regresión Logística para la predicción del conjunto de test. Además, el valor de la ROC AUC de este modelo Logit no supera el valor de 0.6, lo cual lo clasifica como un predictor malo. Para intentar aprender sobre los errores de predicción, se han usado esos mismos modelos para hacer la predicción con el conjunto de entrenamiento y hacer una comparación entre los resultados del conjunto de test y los de entrenamiento. Todos los modelos presentan mejores resultados para el conjunto que entrenamiento que para el de test, y además los modelos de Random Forest y XGBooster sí presentan valores más altos de ROC AUC que el modelo Logit. Sin embargo, la mejor métrica, la del Random Forest, no llega a superar el valor de 0,7, que lo clasifica como un predictor regular. No parece que los modelos hagan overfitting.

Finalmente, para aprender cómo ha sido el entrenamiento del Random Forest, se observa la importancia de los veinte predictores con mayor valor de importancia. Destacan que la PR ya formase parte del hogar desde al menos dos ediciones antes, el valor del interés mostrado por la PR, que el entrevistador considerase que el hogar participó por la relevancia de la encuesta y algunas variables analizadas durante la exploración de los datos, en concreto la tenencia de deudas pendientes, el número de olas en las que ha participado el hogar, que la PR consintiera grabar la entrevista y el nivel educativo de la PR.

A partir de los resultados que se han visto en este proyecto, se plantean las siguientes reflexiones y los posibles pasos que se podrían dar en el futuro para este proyecto:

\begin{enumerate}
    \item \textbf{Revisar la selección de variables:} Un buen modelo predictivo requiere estar construido sobre variables que tengan poder predictivo sobre la variable de interés. Los resultados del análisis descriptivo muestran que las variables seleccionadas tienen relación con la participación de los hogares, pero no tienen suficiente poder para predecir la participación de los hogares en las ediciones siguientes. La selección de variables se inspiró en las implementaciones de \cite{kern2021predicting} y \cite{beste2023case}, que son ejemplos de buenas predicciones de Panel Attrition de hogares. Pero aunque sean encuestas a hogares, tienen métodos de recolección de datos, frecuencias y muestreos diferentes al de la EFF, y en \cite{jankowsky2022validation} mencionan que esos factores pueden afectar a los resultados de los modelos e impedir su generalización a otras encuestas. Afortunadamente, en la EFF se recogen muchas variables que no se han utilizado en este estudio, y su inclusión podría mejorar el rendimiento de los modelos hasta niveles aceptables. Esto abre vías de trabajo futuro continuistas:
    \begin{enumerate}[noitemsep]
        \item Revisar la selección de variables actual, añadir las que se hayan dejado fuera y puedan tener poder predictivo, y eliminar aquellas que puedan estar generando ruido. Implementar procesos de feature selection basados en algoritmos de machine learning.
        \item Hacer un análisis más profundo del error de predicción. En concreto, analizar de manera específica aquellos hogares que los modelos predicen mal y ver qué características tienen.
    \end{enumerate}
    \item \textbf{Plantear un ejercicio explicativo en vez de predictivo:} Todo ejercicio de predicción requiere utilizar variables que se conozcan ex-ante. Por esa razón, los modelos de predicción de Panel Attrition utilizan los datos de ediciones anteriores como predictores. Pero la predicción sólo saldrá bien si esos datos tienen mayor influencia sobre el resultado de la variable objetivo que otras variables que todavía se desconocen. Por ejemplo, el papel del entrevistador es muy importante para conseguir la colaboración de los hogares y para conseguir datos de calidad (\cite{lynn2018tackling} y \cite{groves2006nonresponse}). Pero es imposible saber qué entrevistadores estarán disponibles para el trabajo de campo hasta que llegue el momento de hacer las entrevistas. En este sentido, antes de continuar con el ejercicio predictivo, puede ser interesante utilizar todos los datos disponibles de todas las olas y hacer un análisis explicativo de los factores que determinan la participación de los hogares panel, diferenciando entre variables conocidas ex-ante y variables ex-post, y comprobando cuál de los dos grupos tienen más influencia.
    \item \textbf{El posible papel del Covid-19:} Las olas de la EFF seleccionadas para el estudio son EFF2017, EFF2020 y EFF2022 porque son las que tienen mayor cantidad de datos y también los de mayor calidad. Sin embargo, como se comentó en la sección \ref{chapter:datos}, la pandemia del Covid-19 obligó a cambiar la metodología del campo de la EFF2020 para poder hacer la encuesta respetando las condiciones de seguridad y distancia social. Todos los modelos entrenados utilizan datos de 2017 para predecir 2020, que es año de Covid. Y posteriormente, en el test se utiliza información recogida durante 2020, de nuevo Covid, para predecir 2022, cuando ya se estaba superando la pandemia y fue posible las entrevistas presenciales. Es muy razonable pensar que muchos hogares rechazaron participar en 2020 por miedo al Covid, y también pensar que cambiar el modo de entrevista de personal a teléfónica pudo afectar a los datos. Esto puede implicar que las causas de participación en 2020 sean muy diferentes a las de 2022. Ante esta problemática, se plantean dos posibles alternativas:
    \begin{enumerate}[noitemsep]
        \item \textbf{Hacer un modelo de predicción con los datos de las olas previas a 2020:} La metodología de todas estas olas es homogénea porque todas las entrevistas fueron personales, y no hubo una crisis como la del Covid-19. El inconveniente es que sólo se podría utilizar la información de las respuestas de los hogares. Pero no está claro si necesariamente el rendimiento sería peor.
        \item \textbf{Repetir el actual ejercicio cuando haya más ediciones posteriores a 2020:} La EFF va a continuar realizándose en los próximos años con una frecuencia bienal. Se puede volver a plantear esta misma metodología dentro unos años utilizando sólo ediciones completadas después de 2020, y con el beneficio de recoger toda la información que se recoge actualmente y que no está disponible para antes de 2017.
    \end{enumerate}
    \item\textbf{Cambiar el enfoque:}: Siempre existe la opción de considerar enfoques alternativos sean interesantes y más adecuados para el problema que se quiere abordar. En ese sentido, hay dos alternativas bastante interesantes:
    \begin{enumerate}[noitemsep]
        \item \textbf{Predecir la participación de los paneles en su segunda ola}: En la exploración de los datos se vio que los hogares que han participado sólo en una edición muestran más proporción de abandonos que los que han participado más de dos años. Esto invita a pensar que los hogares que han participado más de una vez están más comprometidos con el estudio, y seguramente merezca la pena enfocar el análisis en la predicción de la participación de los panelistas que sólo han participado una vez en lugar de predecir la participación de todos los hogares.
        \item \textbf{Realizar un análisis de supervivencia:} En vez de predecir un resultado binario, de participar o no participar, se puede plantear hacer un ejercicio de análisis de superviviencia (survival analysis), e intentar predecir el número de ediciones en las que participará un hogar de la EFF antes de abandonar el estudio.
    \end{enumerate}
\end{enumerate}